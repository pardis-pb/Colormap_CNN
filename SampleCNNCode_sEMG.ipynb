{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892d941-e07b-49ad-aa53-11ff582a353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models, layers\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras import callbacks\n",
    "\n",
    "#  Depending on the study, the associated DL model should be imported\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "\n",
    "pretrained_model = ResNet50(input_shape = (224, 224, 3),\n",
    "                               include_top = False,\n",
    "                               weights = 'imagenet', \n",
    "                             pooling = 'max')\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    " \n",
    "#  This section defined the initialisation considerations for a dererministic model. \n",
    "#  If this section is commented, we will hava a stochastic model. \n",
    "# The initialisations are further described in:\n",
    "\n",
    "# R. N. M. Rudd-Orthner and L. Mihaylova, \"Non-Random Weight Initialisation in Deep Learning\n",
    "# Networks for Repeatable Determinism,\" 2019 10th International Conference on Dependable Systems, \n",
    "# Services and Technologies (DESSERT), Leeds, UK, 2019, pp. 223-230, doi: 10.1109/DESSERT.2019.8770007.\n",
    "\n",
    "keras.utils.set_random_seed(42) \n",
    "################## For Linear ramp initialisation - Scheme 2\n",
    "#  It is worth noticing that the number of parameters of the model would affect the \n",
    "# constant values (e.g. 2048*128 && 4*128) of the initialisation. These should be defined before executing the code\n",
    "initval1=np.arange(0,2048*128,1) /(2048*128-1)*0.1-0.05 \n",
    "initval2=np.arange(0,4*128,1)/(4*128-1)*0.1-0.05\n",
    "\n",
    "################## For Sinusoidal initialisation - Scheme 3\n",
    "# initval1 = np.sin(np.arange(0,128*2048,1)/(128*2048-1)*np.pi*2)*0.05\n",
    "# initval2 = np.sin(np.arange(0,4*128,1)/(4*128-1)*np.pi*2)*0.05    \n",
    "\n",
    "\n",
    "#  model configuration\n",
    "model = Sequential()\n",
    "model.add(pretrained_model)\n",
    "model.add (layers.Flatten())\n",
    "model.add(layers.Dense(128, kernel_initializer = tf.constant_initializer(initval1),\n",
    "                 bias_initializer = 'zeros' , activation = 'relu' ))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(4 , kernel_initializer = tf.constant_initializer(initval2),\n",
    "                 bias_initializer = 'zeros' , activation = 'softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aecce5-3117-44f3-ab84-334a028b4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The path to the dataset (the folder containing train and test set) for each specific colormap should be defined\n",
    "DataPath = '../ColorData/Batlow/'\n",
    "\n",
    "img_x , img_y = 224, 224\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "train = ImageDataGenerator(validation_split = 0.2)\n",
    "test = ImageDataGenerator()\n",
    "\n",
    "\n",
    "training1 = train.flow_from_directory(DataPath + 'training/' ,\n",
    "                                          target_size=(img_x , img_y),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'categorical',\n",
    "                                      subset = 'training',\n",
    "                                      seed = 123,\n",
    "                                        shuffle = False)\n",
    "validation1 = train.flow_from_directory(DataPath + 'training/',\n",
    "                                          target_size=(img_x , img_y),\n",
    "                                          batch_size = batch_size,\n",
    "                                          class_mode = 'categorical',\n",
    "                                        seed = 123,\n",
    "                                      subset = 'validation',\n",
    "                                        shuffle = False)                                       \n",
    "testing1 = test.flow_from_directory( DataPath + 'testing/',\n",
    "                                          target_size=(img_x , img_y),\n",
    "                                          batch_size =batch_size,\n",
    "                                          class_mode = 'categorical',\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4cc850-adcc-48d6-b681-449361ecf09d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  The early stopping and callback code should be executed for Schemes 2 to 4. and commented for Scheme 1. \n",
    "\n",
    "# earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "#                                         mode=\"min\", patience= 5,\n",
    "#                                         restore_best_weights=True,\n",
    "#                                        verbose = 1)\n",
    "\n",
    "model.compile(optimizer = Adam(learning_rate= 1e-4),\n",
    "              loss = \"categorical_crossentropy\",\n",
    "              metrics = ['accuracy'])\n",
    "history1 = model.fit(training1, \n",
    "                     validation_data = validation1,\n",
    "                     epochs = 100)\n",
    "                    # callbacks = [earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122912d-b9c0-4c1b-94aa-a092b76f65a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(testing1, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc97ab-cb14-4730-8153-942ba67fcfc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "#  Used for McNemar test\n",
    "true_labels = testing1.classes\n",
    "np.savetxt(sys.stdout, true_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36bd7b-f096-4eb3-90dd-5e4e87f680d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Used for McNemar test\n",
    "predictions = model.predict(testing1)\n",
    "pred_labels = list(np.argmax(predictions, axis=-1))\n",
    "np.savetxt(sys.stdout, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947580d-a44a-47f6-944c-f562b584d44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the confusion plot\n",
    "from sklearn import metrics\n",
    "cm = metrics.confusion_matrix(true_labels, pred_labels)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
